# Emerging Treatmentâ€¯Strategies forâ€¯Headâ€¯&â€¯Neck Cancer  
*BioMCPâ€‘ExamplesÂ â€¢ ResearcherÂ HNSCC*

---

## Original Question  
**â€œWhat are the emerging treatment strategies for head and neck cancer?â€**

---

## Researchers & Example Files

| Letter | Model / Workflow | Answer |
|-------:|------------------|--------|
| **A** | ChatGPTâ€¯Deepâ€¯Research | [`example_a.md`](./example_a.md) |
| **B** | ManusÂ AI | [`example_b.md`](./example_b.md) |
| **C** | Geminiâ€¯Deepâ€¯Research | [`example_c.md`](./example_c.md) |
| **D** | Claudeâ€¯Deepâ€¯Research | [`example_d.md`](./example_d.md) |
| **E** | ClaudeÂ 3.7Â + **BioMCP** + Sequentialâ€‘Thinking + WebÂ Search | [`example_e.md`](./example_e.md) |

> **Background docs for Manusâ€¯AI** live in  
> [`manus_ai_background/`](./manus_ai_background/) â€“ 20â€¯+ source files it cited.

---

## â€œLLMâ€‘asâ€‘Judgeâ€ Prompt  

> **TASK:** Compare, contrast, and forceâ€‘rank EXAMPLESâ€¯Aâ€“E.  
>  â€¢ Create a rubric that *prioritises* **accuracy, clarity, and comprehensiveness**.  
>  â€¢ Add 3â€“5 additional comparison aspects.  
>  â€¢ Grade each example in tables, call out significant inaccuracies or omissions, and provide a final ranked list with reasoning.

The full judge prompt (above) was given verbatim to three largeâ€‘language models acting as reviewers. Their writeâ€‘ups live in **`evals/`**:

| Judge | File |
|-------|------|
| Claudeâ€¯3.7 | [`evals/claude_37.md`](./evals/claude_37.md) |
| Geminiâ€¯2.5â€¯Pro | [`evals/gemini_2_5_pro.md`](./evals/gemini_2_5_pro.md) |
| OpenAIâ€¯o3 | [`evals/openai_o3.md`](./evals/openai_o3.md) |
| *o3 summary* | [`evals/summary_o3.md`](./evals/summary_o3.md) |

Each judge independently built its own rubric, scored the five answers, highlighted factual slips, and produced a forced ranking.

---

## TL;DR of the Judge Consensus â˜…

1. **ExampleÂ E** â€” Widest scope, best structure, but note minor approval misâ€‘statements (dostarlimab).  
2. **ExampleÂ A** â€” Deep immuno/targeted coverage & citations; lighter on radiation/surgical advances.  
3. **ExampleÂ C** â€” Extremely comprehensive (incl. gene/virus therapy); dense prose, a few minor slips.  
4. **ExampleÂ B** â€” Readable overview; shallower evidence & fewer citations.  
5. **ExampleÂ D** â€” Concise executive summary; least comprehensive overall.

*(See individual eval files for the full scoring tables.)*

---

### How to Reâ€‘run or Extend This Study

1. Bring up a BioMCP agent (see the root repo README).  
2. Feed it the original question or tweak as desired.  
3. Compare your new answer with the examples hereâ€”feel free to add yours!

Pull requests with fresh examples, alternate judging frameworks, or new biomedical questions are welcome. ðŸš€

### Note: YouTube Video Run is Different

I recorded a video of this same question with the same prompt, but given
the stochastic nature of LLMs, the response is different. 

You can watch the video here:
[https://youtu.be/tBGG53O-7Hg](https://youtu.be/tBGG53O-7Hg)

And you can read the response of that video run here:
[./biomcp_doc_2/example_e_v2.md](./biomcp_doc_2/example_e_v2.md)